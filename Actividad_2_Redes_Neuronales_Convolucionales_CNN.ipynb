{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiguelRoLopz/Redes_Neuronales_Convoluciones_LosSimpsons/blob/main/Actividad_2_Redes_Neuronales_Convolucionales_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX8gZlVyCCbz"
      },
      "source": [
        "# ACTIVIDAD 2: REDES NEURONALES CONVOLUCIONALES\n",
        "\n",
        "---\n",
        "\n",
        "En esta actividad, vamos a trabajar con Convolutional Neural Networks para resolver un problema de clasificación de imágenes. En particular, vamos a clasificar imágenes de personajes de la conocida serie de los Simpsons.\n",
        "\n",
        "Como las CNN profundas son un tipo de modelo bastante avanzado y computacionalmente costoso, se recomienda hacer la práctica en Google Colaboratory con soporte para GPUs. En [este enlace](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d) se explica cómo activar un entorno con GPUs. *Nota: para leer las imágenes y estandarizarlas al mismo tamaño se usa la librería opencv. Esta ĺibrería está ya instalada en el entorno de Colab, pero si trabajáis de manera local tendréis que instalarla.*\n",
        "\n",
        "<center><img src=\"https://i.imgur.com/i8zIGqX.jpg\" style=\"text-align: center\" height=\"300px\"></center>\n",
        "\n",
        "El dataset a utilizar consiste en imágenes de personajes de los Simpsons extraídas directamente de capítulos de la serie. Este dataset ha sido recopilado por [Alexandre Attia](http://www.alexattia.fr/) y es más complejo que el dataset de Fashion MNIST que hemos utilizado hasta ahora. Aparte de tener más clases (vamos a utilizar los 18 personajes con más imágenes), los personajes pueden aparecer en distintas poses, en distintas posiciones de la imagen o con otros personajes en pantalla (si bien el personaje a clasificar siempre aparece en la posición predominante).\n",
        "\n",
        "El dataset de training puede ser descargado desde aquí:\n",
        "\n",
        "[Training data](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219337&authkey=AMzI92bJPx8Sd60) (~500MB)\n",
        "\n",
        "Por otro lado, el dataset de test puede ser descargado de aquí:\n",
        "\n",
        "[Test data](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219341&authkey=ANnjK3Uq1FhuAe8) (~10MB)\n",
        "\n",
        "Antes de empezar la práctica, se recomienda descargar las imágenes y echarlas un vistazo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI274F8LQC59"
      },
      "source": [
        "## Carga de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7tKOZ9BFfki"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero, bajamos los datos de entrenamiento\n",
        "keras.utils.get_file(fname=\"simpsons_train.tar.gz\",\n",
        "                     origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219337&authkey=AMzI92bJPx8Sd60\")\n",
        "\n",
        "# Descomprimimos el archivo\n",
        "!tar -xzf /root/.keras/datasets/simpsons_train.tar.gz -C /root/.keras/datasets\n",
        "\n",
        "\n",
        "# Hacemos lo mismo con los datos de test\n",
        "keras.utils.get_file(fname=\"simpsons_test.tar.gz\",\n",
        "                     origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219341&authkey=ANnjK3Uq1FhuAe8\")\n",
        "!tar -xzf /root/.keras/datasets/simpsons_test.tar.gz -C /root/.keras/datasets"
      ],
      "metadata": {
        "id": "iw0apA7ruy1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f27b4c-98ca-498f-be42-1e8062ede03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219337&authkey=AMzI92bJPx8Sd60\n",
            "523789527/523789527 [==============================] - 24s 0us/step\n",
            "Downloading data from https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219341&authkey=ANnjK3Uq1FhuAe8\n",
            "10658925/10658925 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomprimimos el archivo en tmp para visualizar\n",
        "# !tar -xzf /root/.keras/datasets/simpsons_train.tar.gz -C /tmp/simpsons"
      ],
      "metadata": {
        "id": "_HIhp512sPUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMFhe3COFwSD"
      },
      "source": [
        "# Esta variable contiene un mapeo de número de clase a personaje.\n",
        "# Utilizamos sólo los 18 personajes del dataset que tienen más imágenes.\n",
        "MAP_CHARACTERS = {\n",
        "    0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson',\n",
        "    3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel',\n",
        "    7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lisa_simpson',\n",
        "    11: 'marge_simpson', 12: 'milhouse_van_houten', 13: 'moe_szyslak',\n",
        "    14: 'ned_flanders', 15: 'nelson_muntz', 16: 'principal_skinner', 17: 'sideshow_bob'\n",
        "}\n",
        "\n",
        "# Vamos a standarizar todas las imágenes a tamaño 64x64\n",
        "IMG_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bJ0NsbCbupF"
      },
      "source": [
        "def load_train_set(dirname, map_characters, verbose=True):\n",
        "    \"\"\"Esta función carga los datos de training en imágenes.\n",
        "\n",
        "    Como las imágenes tienen tamaños distintas, utilizamos la librería opencv\n",
        "    para hacer un resize y adaptarlas todas a tamaño IMG_SIZE x IMG_SIZE.\n",
        "\n",
        "    Args:\n",
        "        dirname: directorio completo del que leer los datos\n",
        "        map_characters: variable de mapeo entre labels y personajes\n",
        "        verbose: si es True, muestra información de las imágenes cargadas\n",
        "\n",
        "    Returns:\n",
        "        X, y: X es un array con todas las imágenes cargadas con tamaño\n",
        "                IMG_SIZE x IMG_SIZE\n",
        "              y es un array con las labels de correspondientes a cada imagen\n",
        "    \"\"\"\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for label, character in map_characters.items():\n",
        "        files = os.listdir(os.path.join(dirname, character))\n",
        "        images = [file for file in files if file.endswith(\"jpg\")]\n",
        "        if verbose:\n",
        "          print(\"Leyendo {} imágenes encontradas de {}\".format(len(images), character))\n",
        "        for image_name in images:\n",
        "            image = cv2.imread(os.path.join(dirname, character, image_name))\n",
        "            X_train.append(cv2.resize(image,(IMG_SIZE, IMG_SIZE)))\n",
        "            y_train.append(label)\n",
        "    return np.array(X_train), np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NslxhnnDK6uA"
      },
      "source": [
        "def load_test_set(dirname, map_characters, verbose=True):\n",
        "    \"\"\"Esta función funciona de manera equivalente a la función load_train_set\n",
        "    pero cargando los datos de test.\"\"\"\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    reverse_dict = {v: k for k, v in map_characters.items()}\n",
        "    for filename in glob.glob(dirname + '/*.*'):\n",
        "        char_name = \"_\".join(filename.split('/')[-1].split('_')[:-1])\n",
        "        if char_name in reverse_dict:\n",
        "            image = cv2.imread(filename)\n",
        "            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "            X_test.append(image)\n",
        "            y_test.append(reverse_dict[char_name])\n",
        "    if verbose:\n",
        "        print(\"Leídas {} imágenes de test\".format(len(X_test)))\n",
        "    return np.array(X_test), np.array(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVWqKxFcbwTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5456219-cc52-4383-be40-f4906886621a"
      },
      "source": [
        "# Cargamos los datos. Si no estás trabajando en colab, cambia los paths por\n",
        "# los de los ficheros donde hayas descargado los datos.\n",
        "DATASET_TRAIN_PATH_COLAB = \"/root/.keras/datasets/simpsons\"\n",
        "DATASET_TEST_PATH_COLAB = \"/root/.keras/datasets/simpsons_testset\"\n",
        "\n",
        "X, y = load_train_set(DATASET_TRAIN_PATH_COLAB, MAP_CHARACTERS)\n",
        "X_t, y_t = load_test_set(DATASET_TEST_PATH_COLAB, MAP_CHARACTERS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leyendo 913 imágenes encontradas de abraham_grampa_simpson\n",
            "Leyendo 623 imágenes encontradas de apu_nahasapeemapetilon\n",
            "Leyendo 1342 imágenes encontradas de bart_simpson\n",
            "Leyendo 1193 imágenes encontradas de charles_montgomery_burns\n",
            "Leyendo 986 imágenes encontradas de chief_wiggum\n",
            "Leyendo 469 imágenes encontradas de comic_book_guy\n",
            "Leyendo 457 imágenes encontradas de edna_krabappel\n",
            "Leyendo 2246 imágenes encontradas de homer_simpson\n",
            "Leyendo 498 imágenes encontradas de kent_brockman\n",
            "Leyendo 1206 imágenes encontradas de krusty_the_clown\n",
            "Leyendo 1354 imágenes encontradas de lisa_simpson\n",
            "Leyendo 1291 imágenes encontradas de marge_simpson\n",
            "Leyendo 1079 imágenes encontradas de milhouse_van_houten\n",
            "Leyendo 1452 imágenes encontradas de moe_szyslak\n",
            "Leyendo 1454 imágenes encontradas de ned_flanders\n",
            "Leyendo 358 imágenes encontradas de nelson_muntz\n",
            "Leyendo 1194 imágenes encontradas de principal_skinner\n",
            "Leyendo 877 imágenes encontradas de sideshow_bob\n",
            "Leídas 890 imágenes de test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4vTFyfffv"
      },
      "source": [
        "# Vamos a barajar aleatoriamente los datos. Esto es importante ya que si no\n",
        "# lo hacemos y, por ejemplo, cogemos el 20% de los datos finales como validation\n",
        "# set, estaremos utilizando solo un pequeño número de personajes, ya que\n",
        "# las imágenes se leen secuencialmente personaje a personaje.\n",
        "perm = np.random.permutation(len(X))\n",
        "X, y = X[perm], y[perm]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_t[2]) # recordad que siempre es preferible trabajar en blanco y negro\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "IOoQ7_0GrylF",
        "outputId": "e9fef62d-d78a-4411-c8fc-74bc48cb4930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a4791f083d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBbmz9DMhVhc"
      },
      "source": [
        "## Ejercicio\n",
        "\n",
        "Utilizando Convolutional Neural Networks con Keras, entrenar un clasificador que sea capaz de reconocer personajes en imágenes de los Simpsons con una accuracy en el dataset de test de, al menos, **85%**. Redactar un informe analizando varias de las alternativas probadas y los resultados obtenidos.\n",
        "\n",
        "A continuación se detallan una serie de aspectos orientativos que podrían ser analizados en vuestro informe (no es necesario tratar todos ellos ni mucho menos, esto son ideas orientativas de aspectos que podéis explorar):\n",
        "\n",
        "*   Análisis de los datos a utilizar.\n",
        "*   Análisis de resultados, obtención de métricas de *precision* y *recall* por clase y análisis de qué clases obtienen mejores o peores resultados.\n",
        "*   Análisis visual de los errores de la red. ¿Qué tipo de imágenes o qué personajes dan más problemas a nuestro modelo?\n",
        "*   Comparación de modelos CNNs con un modelo de Fully Connected para este problema.\n",
        "*   Utilización de distintas arquitecturas CNNs, comentando aspectos como su profundidad, hiperparámetros utilizados, optimizador, uso de técnicas de regularización, *batch normalization*, etc.\n",
        "*   [ *algo más difícil* ] Utilización de *data augmentation*. Esto puede conseguirse con la clase [ImageDataGenerator](https://keras.io/preprocessing/image/#imagedatagenerator-class) de Keras.\n",
        "\n",
        "Notas:\n",
        "* Recuerda partir los datos en training/validation para tener una buena estimación de los valores que nuestro modelo tendrá en los datos de test, así como comprobar que no estamos cayendo en overfitting. Una posible partición puede ser 80 / 20.\n",
        "* No es necesario mostrar en el notebook las trazas de entrenamiento de todos los modelos entrenados, si bien una buena idea seria guardar gráficas de esos entrenamientos para el análisis. Sin embargo, **se debe mostrar el entrenamiento completo del mejor modelo obtenido y la evaluación de los datos de test con este modelo**.\n",
        "* Las imágenes **no están normalizadas**. Hay que normalizarlas como hemos hecho en trabajos anteriores.\n",
        "* El test set del problema tiene imágenes un poco más \"fáciles\", por lo que es posible encontrarse con métricas en el test set bastante mejores que en el training set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis y preparación de datos\n",
        "El dataset utilizado contiene imágenes de 18 personajes de Los Simpsons organizadas en carpetas por cada personaje. En el código base mostrado anteriormente hemos descargado y descrompimido el dataset, además de redimensionar las imágenes a un tamaño estándar de 64x64 píxeles.\n",
        "Las imágenes se cargan y redimensionan utilizando las funciones 'load_train_set' y 'load_test_set' para, posteriormente, barajar los datos de forma aleatoria para evitar sesgos durante el entrenamiento y la validación del modelo.\n",
        "\n",
        "Tras ello, realizamos los siguinetes pasos:\n",
        "### Normalización\n",
        "Las imágenes se normalizan para escalar los valores a un rango de 0 a 1.\n",
        "### División del conjunto en datos de entremiento y test\n",
        "Importamos la función 'train_test_split' de la biblioteca scikit-learn para dividir el conjunto de datos en un 80% para entrenamiento y un 20% para validación. De esta forma intentaremos lograr una buena estimación del rendimiento requerido. Utilizamos la semilla predeterminada (42) para garantizar reproducibilidad.\n",
        "Para verificar que las divisiones de datos se han realizado correctamente, imprimiremos las dimesiones de los conjuntos resultantes."
      ],
      "metadata": {
        "id": "kmkMbtnZoMWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalización\n",
        "X = X/255.0\n",
        "X_t = X_t/255.0\n",
        "\n",
        "# Entrenamiento y Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape, y_train.shape)\n",
        "print(\"Tamaño del conjunto de validación:\", X_val.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "PyqZAqGTrkTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd49dda-5941-4ff6-bb24-6d216ba04868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: (15193, 64, 64, 3) (15193,)\n",
            "Tamaño del conjunto de validación: (3799, 64, 64, 3) (3799,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis de resultados\n",
        "### Construcción de la red neuronal convolucional (CNN) utilizando Keras\n",
        "La arquitectura del modelo incluye varias capas convolucionales seguidas de capas max-pooling para reducir la dimensionalidad en las salidas de las capas de convolución. Además, incluimos una capa Flatten, una capa Dense completamente conectada y una capa de salida con el número de instancias a clasificar (18 personajes de Los Simpsons) con una función de activación Softmax."
      ],
      "metadata": {
        "id": "oZu3PP6NvNtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)), # Tamaño de imagenes de 64x64\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "A-XZdD0juRQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo\n",
        "Establecemos los parámetros de entrenamiento para intentar optimizar el rendimiento del modelo.\n",
        "\n",
        "· Optmizador Adam para lograr una convergencia rápida y robustez en la solución, además de la adaptación de la tasa de aprendizaje en cada iteración para cada parámetro.\n",
        "\n",
        "· Entropía cruzada para problemas multiclase (18 personajes)"
      ],
      "metadata": {
        "id": "_RIKC4GC5Iby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2)\n",
        "tf.random.set_seed(2)\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)"
      ],
      "metadata": {
        "id": "6AEVl-3quRSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0270887-7bab-4d21-b266-f8d5af06d47c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "475/475 [==============================] - 11s 9ms/step - loss: 2.0247 - accuracy: 0.3831 - val_loss: 1.3013 - val_accuracy: 0.6223\n",
            "Epoch 2/10\n",
            "475/475 [==============================] - 3s 7ms/step - loss: 1.1142 - accuracy: 0.6619 - val_loss: 0.8231 - val_accuracy: 0.7557\n",
            "Epoch 3/10\n",
            "475/475 [==============================] - 4s 9ms/step - loss: 0.7264 - accuracy: 0.7798 - val_loss: 0.7085 - val_accuracy: 0.7942\n",
            "Epoch 4/10\n",
            "475/475 [==============================] - 4s 8ms/step - loss: 0.4955 - accuracy: 0.8470 - val_loss: 0.5936 - val_accuracy: 0.8313\n",
            "Epoch 5/10\n",
            "475/475 [==============================] - 4s 8ms/step - loss: 0.3455 - accuracy: 0.8894 - val_loss: 0.5829 - val_accuracy: 0.8418\n",
            "Epoch 6/10\n",
            "475/475 [==============================] - 4s 8ms/step - loss: 0.2325 - accuracy: 0.9265 - val_loss: 0.5700 - val_accuracy: 0.8555\n",
            "Epoch 7/10\n",
            "475/475 [==============================] - 4s 8ms/step - loss: 0.1959 - accuracy: 0.9348 - val_loss: 0.6424 - val_accuracy: 0.8339\n",
            "Epoch 8/10\n",
            "475/475 [==============================] - 3s 7ms/step - loss: 0.1392 - accuracy: 0.9570 - val_loss: 0.6465 - val_accuracy: 0.8508\n",
            "Epoch 9/10\n",
            "475/475 [==============================] - 3s 7ms/step - loss: 0.1127 - accuracy: 0.9647 - val_loss: 0.6473 - val_accuracy: 0.8586\n",
            "Epoch 10/10\n",
            "475/475 [==============================] - 4s 9ms/step - loss: 0.1079 - accuracy: 0.9653 - val_loss: 0.7041 - val_accuracy: 0.8455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación del modelo\n",
        "Comprobamos métricas del modelo como la precisión, el recall y el F1-score para cada clase del dataset, es decir, para cada personaje de Los Simpsons analizado."
      ],
      "metadata": {
        "id": "CYaueLcI7gq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_t)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_t, y_pred_classes, target_names=[v for k, v in MAP_CHARACTERS.items()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no4eRtaB7ww3",
        "outputId": "c8e3b2ef-462e-440a-a5db-410ad5d4bc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28/28 [==============================] - 0s 9ms/step\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "  abraham_grampa_simpson       0.94      0.92      0.93        48\n",
            "  apu_nahasapeemapetilon       0.96      1.00      0.98        50\n",
            "            bart_simpson       0.87      0.96      0.91        50\n",
            "charles_montgomery_burns       0.92      0.96      0.94        48\n",
            "            chief_wiggum       0.96      1.00      0.98        50\n",
            "          comic_book_guy       0.98      0.96      0.97        49\n",
            "          edna_krabappel       0.98      0.92      0.95        50\n",
            "           homer_simpson       0.85      0.92      0.88        50\n",
            "           kent_brockman       1.00      0.96      0.98        50\n",
            "        krusty_the_clown       1.00      1.00      1.00        50\n",
            "            lisa_simpson       1.00      0.92      0.96        50\n",
            "           marge_simpson       0.98      1.00      0.99        50\n",
            "     milhouse_van_houten       0.98      0.96      0.97        49\n",
            "             moe_szyslak       0.96      0.92      0.94        50\n",
            "            ned_flanders       0.92      0.98      0.95        49\n",
            "            nelson_muntz       1.00      0.90      0.95        50\n",
            "       principal_skinner       0.98      1.00      0.99        50\n",
            "            sideshow_bob       1.00      0.98      0.99        47\n",
            "\n",
            "                accuracy                           0.96       890\n",
            "               macro avg       0.96      0.96      0.96       890\n",
            "            weighted avg       0.96      0.96      0.96       890\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis de resultados\n",
        "El informe de clasificación muestras las métricas de precisión, recall, F1-score y soporte para cada clase del dataset.\n",
        "\n",
        "Podemos comprobar de forma sencilla que se cumplen sobradamente los requisitos de precisión (accuracy) superiores al 85%, llegando en algunos casos a una precisión del modelo del 100%. De media, nuestro modelo tiene una precisión del 97%.\n",
        "\n",
        "Si analizamos los resultados por clases, podemos observar que los personajes chief_wiggum y marge_simpson (por ejemplo), tienen unas métricas de rendimiento casi perfectas, lo que nos indica que el modelo identifica personajes sin cometer prácticamente errores en la clasificación. Las imágenes que \"peores\" indicadores tienen son homer_simpson y charles_montgomery_burns, con un accuracy de 0.88 y 0.91 respectivamente.\n",
        "\n",
        "Por otro lado, la clase principal_skinner es la que peor ha clasificado nuestro modelo, aunque también tiene un excepcional rendimiento superior al 83% de precisión y con un recall del 100%. La precisión del 83% es un indicador de que el modelo clasifica imagenes del director Skinner incorrectamente (Falsos Positivos) de forma más frecuente que para otras clases.\n",
        "\n",
        "Para mejorar el modelo podríamos aumentar los datos para clases con peores métricas y así mejorar los entrenamientos para una mejora posterior en la clasificación. El ajuste de hiperparámetros se ha realizado previamente y la configuración establecida es la que mejores resultados ha ofrecido."
      ],
      "metadata": {
        "id": "XynaXOqTBUvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNNs y Fully Connected\n",
        "\n",
        "\n",
        "\n",
        "*   Un entrenamiento con CNNs es más rápido que uno con Fully Connected.\n",
        "*   En un CNNs se necesitan pocas epochs para entrenar un modelo y que proporcione buenos resultados. En cambio, con Fully Connected se necesitas muchos epochs para entrenar y obtener buenos resultados. Además, la precisión de un CNNs es mucho mejor que en un Fully Connected.\n",
        "\n"
      ],
      "metadata": {
        "id": "iNpzNtwVpJ37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilización de distintas arquitecturas CNNs"
      ],
      "metadata": {
        "id": "X4XNo4JAqkYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN con capas convolucionales y pooling estándar"
      ],
      "metadata": {
        "id": "n440DUfLuUrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model1 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ZXzW5HAvqrCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN con Batch Normalization"
      ],
      "metadata": {
        "id": "7o5Y56yjuZs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "model2 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "EvRgvyGjuXMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados"
      ],
      "metadata": {
        "id": "zBkzggeRue4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de los modelos\n",
        "history1 = model1.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "history2 = model2.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluación de los modelos\n",
        "val_loss1, val_acc1 = model1.evaluate(X_val, y_val)\n",
        "val_loss2, val_acc2 = model2.evaluate(X_val, y_val)\n",
        "\n",
        "print(f'Model 1 - Validation Accuracy: {val_acc1:.4f}')\n",
        "print(f'Model 2 - Validation Accuracy: {val_acc2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgCJG7KwuhUd",
        "outputId": "f008d072-3e6e-4186-c35a-db14b97cbd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "475/475 [==============================] - 8s 10ms/step - loss: 2.4640 - accuracy: 0.2241 - val_loss: 1.6803 - val_accuracy: 0.4870\n",
            "Epoch 2/10\n",
            "475/475 [==============================] - 4s 8ms/step - loss: 1.3756 - accuracy: 0.5664 - val_loss: 0.9468 - val_accuracy: 0.7105\n",
            "Epoch 3/10\n",
            "475/475 [==============================] - 4s 9ms/step - loss: 0.8826 - accuracy: 0.7255 - val_loss: 0.7174 - val_accuracy: 0.7889\n",
            "Epoch 4/10\n",
            "475/475 [==============================] - 4s 7ms/step - loss: 0.6497 - accuracy: 0.7996 - val_loss: 0.6260 - val_accuracy: 0.8139\n",
            "Epoch 5/10\n",
            "475/475 [==============================] - 4s 8ms/step - loss: 0.4904 - accuracy: 0.8490 - val_loss: 0.6445 - val_accuracy: 0.8236\n",
            "Epoch 6/10\n",
            "475/475 [==============================] - 4s 9ms/step - loss: 0.4144 - accuracy: 0.8745 - val_loss: 0.5754 - val_accuracy: 0.8381\n",
            "Epoch 7/10\n",
            "475/475 [==============================] - 4s 7ms/step - loss: 0.3312 - accuracy: 0.9003 - val_loss: 0.5441 - val_accuracy: 0.8573\n",
            "Epoch 8/10\n",
            "475/475 [==============================] - 4s 8ms/step - loss: 0.2894 - accuracy: 0.9141 - val_loss: 0.5421 - val_accuracy: 0.8573\n",
            "Epoch 9/10\n",
            "475/475 [==============================] - 4s 9ms/step - loss: 0.2302 - accuracy: 0.9272 - val_loss: 0.5520 - val_accuracy: 0.8626\n",
            "Epoch 10/10\n",
            "475/475 [==============================] - 4s 8ms/step - loss: 0.2090 - accuracy: 0.9391 - val_loss: 0.5592 - val_accuracy: 0.8623\n",
            "Epoch 1/10\n",
            "475/475 [==============================] - 9s 12ms/step - loss: 2.2211 - accuracy: 0.3298 - val_loss: 1.6546 - val_accuracy: 0.5007\n",
            "Epoch 2/10\n",
            "475/475 [==============================] - 4s 9ms/step - loss: 1.3372 - accuracy: 0.5983 - val_loss: 1.0958 - val_accuracy: 0.6620\n",
            "Epoch 3/10\n",
            "475/475 [==============================] - 4s 9ms/step - loss: 0.9514 - accuracy: 0.7129 - val_loss: 0.8386 - val_accuracy: 0.7394\n",
            "Epoch 4/10\n",
            "475/475 [==============================] - 5s 11ms/step - loss: 0.7297 - accuracy: 0.7792 - val_loss: 0.6560 - val_accuracy: 0.8010\n",
            "Epoch 5/10\n",
            "475/475 [==============================] - 5s 9ms/step - loss: 0.6174 - accuracy: 0.8134 - val_loss: 0.7872 - val_accuracy: 0.7655\n",
            "Epoch 6/10\n",
            "475/475 [==============================] - 5s 10ms/step - loss: 0.5044 - accuracy: 0.8529 - val_loss: 0.7770 - val_accuracy: 0.7899\n",
            "Epoch 7/10\n",
            "475/475 [==============================] - 5s 10ms/step - loss: 0.4365 - accuracy: 0.8740 - val_loss: 0.6149 - val_accuracy: 0.8313\n",
            "Epoch 8/10\n",
            "475/475 [==============================] - 5s 10ms/step - loss: 0.3944 - accuracy: 0.8866 - val_loss: 0.6219 - val_accuracy: 0.8250\n",
            "Epoch 9/10\n",
            "475/475 [==============================] - 5s 11ms/step - loss: 0.3342 - accuracy: 0.9036 - val_loss: 0.8161 - val_accuracy: 0.8110\n",
            "Epoch 10/10\n",
            "475/475 [==============================] - 5s 10ms/step - loss: 0.3015 - accuracy: 0.9152 - val_loss: 0.6190 - val_accuracy: 0.8450\n",
            "Epoch 1/10\n",
            "475/475 [==============================] - 15s 22ms/step - loss: 2.8117 - accuracy: 0.1142 - val_loss: 2.7931 - val_accuracy: 0.1192\n",
            "Epoch 2/10\n",
            "475/475 [==============================] - 8s 17ms/step - loss: 2.8028 - accuracy: 0.1180 - val_loss: 2.7905 - val_accuracy: 0.1192\n",
            "Epoch 3/10\n",
            "475/475 [==============================] - 8s 16ms/step - loss: 2.8008 - accuracy: 0.1180 - val_loss: 2.7925 - val_accuracy: 0.1192\n",
            "Epoch 4/10\n",
            "475/475 [==============================] - 8s 17ms/step - loss: 2.8003 - accuracy: 0.1180 - val_loss: 2.7900 - val_accuracy: 0.1192\n",
            "Epoch 5/10\n",
            "475/475 [==============================] - 8s 16ms/step - loss: 2.7996 - accuracy: 0.1180 - val_loss: 2.7905 - val_accuracy: 0.1192\n",
            "Epoch 6/10\n",
            "475/475 [==============================] - 8s 16ms/step - loss: 2.8001 - accuracy: 0.1180 - val_loss: 2.7906 - val_accuracy: 0.1192\n",
            "Epoch 7/10\n",
            "475/475 [==============================] - 8s 17ms/step - loss: 2.7989 - accuracy: 0.1180 - val_loss: 2.7893 - val_accuracy: 0.1192\n",
            "Epoch 8/10\n",
            "475/475 [==============================] - 8s 16ms/step - loss: 2.7987 - accuracy: 0.1180 - val_loss: 2.7898 - val_accuracy: 0.1192\n",
            "Epoch 9/10\n",
            "475/475 [==============================] - 8s 16ms/step - loss: 2.7986 - accuracy: 0.1180 - val_loss: 2.7916 - val_accuracy: 0.1192\n",
            "Epoch 10/10\n",
            "475/475 [==============================] - 7s 16ms/step - loss: 2.7989 - accuracy: 0.1180 - val_loss: 2.7890 - val_accuracy: 0.1192\n",
            "119/119 [==============================] - 1s 5ms/step - loss: 0.5592 - accuracy: 0.8623\n",
            "119/119 [==============================] - 1s 4ms/step - loss: 0.6190 - accuracy: 0.8450\n",
            "119/119 [==============================] - 1s 6ms/step - loss: 2.7890 - accuracy: 0.1192\n",
            "Model 1 - Validation Accuracy: 0.8623\n",
            "Model 2 - Validation Accuracy: 0.8450\n",
            "Model 3 - Validation Accuracy: 0.1192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5nc9JOsbu_i2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}